/**
 * 인코딩과 디코딩(encoding & decoding)
 * 
 * 컴퓨터는 숫자밖에 모르기 때문에 문자가 숫자로 변환되어 저장된다.
 * ex) unicode : 문자(A) => 유니코드(65)
 * 
 * (1)ASCII(아스키)
 * Amerikcan Standard Code for information Interchange
 * 정보교환을 위한 미국 표준 코드
 * 아스키는 128개(2^7)의 문자 집합(character set)을 제공하는 7bit 부호
 * 처음 32개 문자는 인쇄와 전송 제어용으로 사용되는 '제어문자(control character)'
 * 마지막 문자(DEL)를 제외한 33번째 이후의 문자들은 출력할 수 있는 문자들, 기호와 숫자, 영대소문자로 이뤄짐
 * 
 * (2)Extended ASCII(확장 아스키)
 * 일반적으로 데이터는 byte단위로 다뤄지는데 아스키는 7 bit라 1bit가 남는다.
 * 이 남은 1bit 공간을 활용해서 문자를 추가로 정의한 것이 '확장 아스키'이다.
 * 확장 아스키에 추가된 128개의 문자는 여러 국가와 기업에서 서로의 필요에 따라 다르게 정의해서 사용한다.
 * 
 * 'ISO(국제표준화기구)'에서 확장 아스키의 표준을 몇 가지 발표했는데, 그중에서 대표적인 것은 ISO 8859-1
 * ISO 8859-1 : ISO Latin 1이라고도 한다.
 * 문제는 문자의 갯수가 255개뿐이라 한글로 표현하기엔 한계가 있다.
 * 그래서 조합형과 완성형으로 표현함
 * 조합형 : 초성, 중성, 종성을 조합하는 방식
 * 완성형 : 확장 아스키의 일부 영역(162~254)에 해당하는 두 문자코드를 조합하여 한글로 표현
 * 
 * 현재 조합형은 사용되지 않고 완성형(KSC 5601)에 없는 잘 안쓰이는 8822글자를 추가한
 * '확장 완성형(CP 949)'이 사용되고, 이것이 바로 한글 윈도우에서 쓰는 문자 인코딩임.
 * 
 * (3)Code Page(코드 페이지, CP)
 * IBM이 자사 PC에 Extended ASCII를 도입해서 사용할 때 지역이나 국가에 따라 여러 확장 아스키가 필요했음
 * 이들을 code page라고 하고 'CP xxx'와 같은 형식으로 이름을 붙임
 * 
 * 한글 Window : CP 949
 * 영문 Window : CP 437
 * 
 * (4)Unicode(유니코드)
 * 인터넷이 발전하면서 서로 다른 인코딩을 사용하는 컴퓨터간의 문서교환에 어려움
 * 전 세계의 모든 문자를 하나의 통일된 문자집합으로 표현하고 싶음 => 유니코드
 * 
 *  처음엔 모든 문자를 2 byte로 표현하려 했으나 부족 -> 21 bit로 확장
 *  새로 추가된 문자들을 보충 문자(supplementary character)라 하고
 *  이 문자들을 표현하기 위해서는 char타입이 아닌 int타입을 사용해야 한다.
 *  그러나 우리가 보충문자를 쓸 일은 거의 없다.
 *  
 *  유니코드는 먼저 유니코드에 포함시키고자 하는 문자들의 집합을 정의했는데 이것을 character set이라 함
 *  이 문자 셋에 번호를 붙인 것이 유니코드 인코딩이다.
 *  UTF-8, UTF-16, UTF-32 등 여러 버전이 있고 자바에서는 UTF-16을 사용한다.
 *  UTF-16은 모든 문자를 2 byte의 고정크기로 표현
 *  UTF-8 은 하나의 문자를 1~4 byte의 가변크기로 표현
 *  UTF-16, UTF-8 두 인코딩 모두 처음 128문자가 아스키와 동일함, 즉 아스키를 그대로 포함하고 있음
 *  
 *  UTF-16은 문자 크기가 고정되어있어 문자를 다루기 편함, but 1 byte로 표현가능한 영어, 숫자도 2 byte...
 *  즉, 문서의 크기가 커진다.
 *  
 *  UTF-8은 영문과 숫자는 1 byte, 한글은 3 byte로 표현됨
 */
package series.fun.java;